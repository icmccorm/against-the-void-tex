One approach to understanding the role of \unsafe code is to evaluate it as it is written. Evans et al.~\cite{evans20} and Astrauskas et al.~\cite{astrauskas20} conducted surveys of Rust crates 16 months apart and found that 29\% and 23.6\% of crates contained \unsafe code, respectively. Each study used different methods, but both observed that most \unsafe code blocks were relatively small and that \unsafe function calls were the most common \unsafe operation. Each study also categorized developers' motivations for using \unsafe code. Astrauskas et al.~\cite{astrauskas20} extracted motivations from patterns observed in code, and Evans et al.~\cite{evans20} created a community survey that reached 50 Rust developers on Reddit. However, in each study, initial motivations were defined without direct engagement with developers and include topics which are more adequately described as use-cases for \unsafe code, such as calling foreign functions and implementing cyclic aliasing patterns.

Other researchers have manually inspected bug reports and security vulnerabilities to understand the risks of using \unsafe code incorrectly. Both Qin et al.~\cite{qin20} and Xu et al.~\cite{xu2021} found that discrepancies between the signature of a safe API and its interior \unsafe implementation are a significant source of vulnerabilities. Cui et al.~\cite{cui23} focus on \unsafe APIs in Rust's standard library and define 19 distinct safety properties that occur as preconditions or postconditions. These approaches illustrate that it is difficult to correctly encapsulate \unsafe code, but they, too, have limited engagement with developers. Cui et al.~\cite{cui23} conducted a survey to evaluate their classification, but they did not investigate developers' experiences with reasoning about safety properties.

Fulton et al.~\cite{fulton21} used a similar mixed methods design to ours, which consisted of interviews followed by a survey. They found that most participants had used \unsafe code and the most common use case was calling foreign functions. Their approach was effective at evaluating the overall strengths and drawbacks of Rust as a systems programming language, but they only briefly discussed \unsafe features. 
 
HÃ¶ltervennhoff et al.~\cite{holtervennhoff23} are the only other group to use qualitative methods to study Rust developers' use of \unsafe code. They conducted semi-structured interviews with 26 developers, and similar to us, they examined developers' motivations for using \unsafe code and their practices for API design. We compare our findings with theirs when discussing the results of our first and second research questions in sections~\ref{results:rq1} and~\ref{results:rq2}. However, beyond these findings, our goals and results differ. They primarily focus  on evaluating developers' security practices when using \unsafe code, while we were interested in the challenges developers face when calling foreign functions, the effectiveness of tooling, and the Rust community's perception of \unsafe code.

%Participants inevitably used \unsafe code for foreign function calls, but they also used it when it would perform better or took less effort to implement than a safe pattern. They prioritized encapsulating \unsafe code, attempted to keep it minimal, and documented safety requirements. However, participants often relied on ``common sense and trust'' for validation and felt unsure about soundness due to Rust's evolving semantics. 
