The Rust programming language has been a consistently popular choice for systems programming~\cite{stackoverflow_dev_survey23} due to its competitive performance~\cite{pereira17} and static safety guarantees. These guarantees are provided by Rust's borrow checker, which restricts aliasing and mutability to prevent types of errors that can lead to security vulnerabilities, such as access out-of-bounds and double free~\cite{qin20}. These restrictions are helpful, but they are also conservative; there are safe design patterns that the borrow checker cannot validate. When necessary, Rust developers can use the \unsafe keyword to enable features that bypass Rust's restrictions. 

Rust's \unsafe features are central to its design and at the foundation of its ecosystem~\cite{astrauskas20,evans20}.  However, if \unsafe code is misused, it can undermine Rust's core promise of static safety. Using \unsafe code correctly is not a trivial task; Rust's aliasing restrictions are challenging to reason about~\cite{zhu22} and they constrain the soundness of unsafe operations~\cite{stacked_borrows}. Dynamic analysis tools like Miri~\cite{miri} and Valgrind~\cite{seward07} can find problems automatically, but they are underused and may miss bugs related to multi-language interoperation. Understanding developers' motivations for using \unsafe code and their methods for reasoning about its soundness is necessary to determine which interventions will be effective. To that end, we address the following research questions:

\rsqone We identify three distinct motivations that developers cite to justify their use of \unsafe code, which are not mutually exclusive.

\rsqtwo We outline how developers reason about safety when encapsulating \unsafe code. We describe the extent to which developers can ensure that \unsafe code is minimal and isolated. Then, we examine why developers choose to expose \unsafe interfaces and whether these interfaces are documented.

\rsqthree 
We describe how developers reason about interoperating with foreign libraries, and we identify disparities between Rust's memory model and foreign memory models that may lead to undefined behavior.  

\rsqfour We explore the role of testing, auditing, and dynamic analysis tools in Rust developers' workflows. We focus on Miri~\cite{miri}, which is the only dynamic bug-finding tool capable of validating \unsafe code against Rust's current operational semantics. We determine how frequently Miri is used and identify key limitations that deter developers from using it. 

\rsqfive We investigate how \unsafe code is perceived by the Rust community and we determine whether current documentation and community guidelines meet developers' needs.  

To answer these questions, we used a mixed-methods approach consisting of semi-structured interviews with \ArrayItem{responses.screening.valid} Rust developers followed by a survey that had \ArrayItem{responses.survey.valid} valid responses. Our findings demonstrate that several key qualitative results from Holtervenhoff et al.~\cite{holtervennhoff23}, who interviewed 26 participants, generalize to our population of 179 developers. That is, developers prioritize keeping \unsafe code minimal, encapsulated, and well-documented, but they rarely audit their dependencies and rely on ad-hoc reasoning to justify their decisions. Additionally, we find new evidence that \unsafe code is not regularly tested and that validation tools, such as Miri and cargo-audit\cite{cargoaudit}, are underutilized. 

Our findings indicate that when developers feel that there is no alternative other than using \unsafe code, Rust does not provide adequate resources to ensure that they are not abandoning safety altogether. This correctness gap can be addressed by improved support for validating certain \unsafe features in existing tools, such as Miri. Likewise, any future approaches to verification should provide robust support for \unsafe features while remaining lightweight, intuitive, and tightly integrated with the Rust toolchain. Meanwhile, the Rust community must proactively spread awareness that tool-supported auditing and verification are necessary to make Rust's promise of static safety a reality.